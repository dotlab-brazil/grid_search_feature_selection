{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura Dataframes e resultados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Enviar reqs para o bot\n",
    "import requests\n",
    "\n",
    "#Acessar print do sistema\n",
    "import sys\n",
    "\n",
    "#Libs para gerar o tempo\n",
    "import time\n",
    "import calendar\n",
    "\n",
    "# Classificadores\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Grid_search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Feature Selection\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# Example\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de configura√ß√£o do bot\n",
    "TELEGRAM_TOKEN = \"TOKEN_HERE\"\n",
    "  # TOKEN example 5298243636:AAGFB9MK3NyrJd9FstfhgVM0Pq95SCEZqfg\n",
    "CHAT_ID = \"CHAT_ID\"\n",
    "# CHAT EXAMPLE -761539976\n",
    "EXPERIMENTO_ID = \"ID\" #Id pra diferenciar cada experimento\n",
    "\n",
    "#Configura√ß√£o do Experimento\n",
    "K_FOLD = 2\n",
    "MODELO = AdaBoostClassifier()\n",
    "SEED = 42 #Resposta final da vida, do universo e tudo\n",
    "\n",
    "#base de dados\n",
    "# database_path = \"/home/ubuntu/base_dados/com_undersampling/baseCompleta-1617664035.csv\"\n",
    "output_feature = \"target\"\n",
    "results_path = \"/home/thomas/Documentos/mestrado/results\"\n",
    "\n",
    "'''\n",
    "Array de parametros para rodar no gridSearch\n",
    "parametros do modelo sao iniciados com \"sfs__estimator__\"\n",
    "parametros do sfs sao iniciados com \"sfs__\"\n",
    "'''\n",
    "param_grid = [{\n",
    "    # 'sfs__forward': [True, False],\n",
    "    # 'sfs__floating': [True, False],\n",
    "    # 'sfs__estimator__n_estimators': [25,50,100],\n",
    "    'learning_rate': [0.36, 1., 1.5],\n",
    "}]\n",
    "\n",
    "total_comb = K_FOLD\n",
    "for key in param_grid[0].keys():\n",
    "  total_comb = total_comb * len(param_grid[0][key])\n",
    "\n",
    "timestamp = calendar.timegm(time.gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_bot(bot_message):\n",
    "    '''\n",
    "    Descri√ß√£o:\n",
    "        Envia a mensagem desejada para o chat desejado atraves do bot do telegram\n",
    "    Entrada:\n",
    "        bot_message\n",
    "            string com a mensagem\n",
    "    Var_Config:\n",
    "        TELEGRAM_TOKEN:\n",
    "            Token do bot do telegram\n",
    "        CHAT_ID:\n",
    "            id do chat para onde a mensagem sera enviada\n",
    "        EXPERIMENTO_ID:\n",
    "            Id de identificacao para saber de qual experimento ser√° a mensagem\n",
    "    '''\n",
    "    \n",
    "    bot_message = EXPERIMENTO_ID+\"->\"+bot_message\n",
    "    bot_token = TELEGRAM_TOKEN\n",
    "    bot_chatID = CHAT_ID\n",
    "    # url BASE https://api.telegram.org/bot<BOT_TOKEN/sendMessage?chat_id=<CHAT_ID>&text=<MESSAGE>\n",
    "    send_text = 'https://api.telegram.org/bot' + bot_token + '/sendMessage?chat_id=' + bot_chatID + '&text=' + bot_message\n",
    "\n",
    "    response = requests.get(send_text)\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Com esse bloco todo print feito no projeto ser√° encaminhado para o bot e salvo em um arquivo de log\n",
    "O nome do arquivo de log √© feito com base no timestamp de quando o experimento foi iniciado\n",
    "O atributo 'bot_print' serve para impedir de ser enviado para o bot, em casos onde as mensagem serao muitos grandes\n",
    "No experimento quando e printado todos os resultados do grid search, nao e enviado para o bot\n",
    "\n",
    "No ultimo bloco de codigo e necessario o comando 'sys.stdout = orig_stdout' para desativar a classe e o arquivo \n",
    "de log ser salvo\n",
    "'''\n",
    "\n",
    "nome_arquivo = \"relatorio-\"+EXPERIMENTO_ID+\"-\"+str(timestamp)+\".log\"\n",
    "path_log = results_path + \"/\"+nome_arquivo\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(path_log, \"a\")\n",
    "        self.contador = 0\n",
    "\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "        if (message not in \"\\n\"):\n",
    "          if (message.startswith('[CV]')):\n",
    "            self.contador = self.contador + 1\n",
    "            # if ((self.contador%2) == 0 and self.contador != 0):\n",
    "            info = (f\"{self.contador}/{total_comb} conclu√≠dos‚úÖ\")\n",
    "            message = message + \"\\n\" + info\n",
    "          print_bot(message)\n",
    "\n",
    "    def flush(self):\n",
    "        #this flush method is needed for python 3 compatibility.\n",
    "        #this handles the flush command by doing nothing.\n",
    "        #you might want to specify some extra behavior here.\n",
    "        pass  \n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "sys.stdout = Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura e divisao da base de dados\n",
    "# df = pd.read_csv(database_path, sep=\";\")\n",
    "df = datasets.load_iris()\n",
    "# print(f'Initial shape: {df.shape}')\n",
    "\n",
    "# X = df.drop(output_feature, axis=1)\n",
    "X = df.data\n",
    "y = df[output_feature]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Iniciando as libs\n",
    "\n",
    "O SFS sera executado com n_jobs=-1 para aproveitar todo o processamento da maquina\n",
    "O subconjuhnto sera avaliado pela accuracy\n",
    "\n",
    "O gridSearch sera executado com n_jobs=1 para ser possivel observar sua evolucao, alem de que o SFS ja estara co n_jobs=-1,\n",
    "entao nao sera necessario manter o -1 nele tambem\n",
    "a selecao da melhor configuracao sera feita atraves da accuracy\n",
    "\n",
    "No fim sera possivel adquirir o relatorio de feature selection apenas da melhor configuracao, para analises posteriores\n",
    "a acuracia de todos as combinacoes tambem sera salva no arquivo de log para analise posterior\n",
    "'''\n",
    "\n",
    "sfs = SFS(\n",
    "  estimator=MODELO, \n",
    "  k_features=(1,X.shape[1]), \n",
    "  scoring='accuracy',\n",
    "  cv=K_FOLD,\n",
    "  n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('sfs', sfs), \n",
    "  ('modelo', MODELO)])\n",
    "\n",
    "gs = GridSearchCV(\n",
    "  estimator=MODELO, \n",
    "  param_grid=param_grid, \n",
    "  scoring='accuracy', \n",
    "  n_jobs=-1, \n",
    "  cv=K_FOLD,\n",
    "  refit=True,\n",
    "  verbose=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando grid search üíª\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "[CV 2/2] END .................learning_rate=1.5;, score=0.904 total time=   0.2s\n",
      "[CV 2/2] END .................learning_rate=1.0;, score=0.923 total time=   0.2s\n",
      "[CV 1/2] END .................learning_rate=1.0;, score=0.887 total time=   0.2s\n",
      "[CV 1/2] END .................learning_rate=1.5;, score=0.887 total time=   0.2s\n",
      "[CV 1/2] END ................learning_rate=0.36;, score=0.887 total time=   0.1s\n",
      "[CV 2/2] END ................learning_rate=0.36;, score=0.904 total time=   0.1s\n",
      "Finalizado ü§©ü•≥üéâ\n",
      "‚öôÔ∏èBest params: {'learning_rate': 1.0}\n",
      "üìäAcc: 0.9049346879535559\n",
      "Finalizei o meu trabalho, at√© a pr√≥xima üòâ\n"
     ]
    }
   ],
   "source": [
    "#Execucao do experimento, caso algum erro ocorra durante o experimento, a val ira avisar\n",
    "\n",
    "try:\n",
    "    print('Iniciando grid search üíª')\n",
    "    gs.fit(X_train,y_train)\n",
    "    print('Finalizado ü§©ü•≥üéâ')\n",
    "    \n",
    "    #melhores resultados\n",
    "    # print(f'üîéBest features: {gs.best_estimator_.steps[0][1].k_feature_names_}')\n",
    "    print(f'‚öôÔ∏èBest params: {gs.best_params_}')\n",
    "    print(f'üìäAcc: {gs.best_score_}')\n",
    "    \n",
    "    # #salvando o dataframe com o relatorio das features do melhor\n",
    "    # rel_sfs = gs.best_estimator_.steps[0][1]\n",
    "    # results_df = pd.DataFrame.from_dict(rel_sfs.get_metric_dict()).T\n",
    "    # results_df.to_csv(f'{results_path}/sfs_best-{EXPERIMENTO_ID}-{str(timestamp)}.csv', index=False)\n",
    "    \n",
    "    #salvando dataframe do gridSearch\n",
    "    gs_df = pd.DataFrame(gs.cv_results_)\n",
    "    gs_df.to_csv(f'{results_path}/grid_search-{EXPERIMENTO_ID}-{str(timestamp)}.csv', index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f'Infelizmente, ocorreu um erro üòî')\n",
    "print(f'Finalizei o meu trabalho, at√© a pr√≥xima üòâ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setando a saida para o padrao e salvando arquivo de log\n",
    "sys.stdout = orig_stdout"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2af68a4b51633f13995ebfae92a57b161ed6e58c9d8595f65fa30edeb049295"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
